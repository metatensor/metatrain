{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Using metatrain architectures outside of metatrain\n\nThis tutorial demonstrates how to use one of metatrain's implemented architectures\noutside of metatrain. This will be done by taking internal representations of a\nNanoPET model (as an example) and using them inside a user-defined torch ``Module``.\n\nOnly architectures which can output internal representations (\"features\" output) can\nbe used in this way.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom metatomic.torch import ModelOutput\n\nfrom metatrain.pet import PET\nfrom metatrain.utils.architectures import get_default_hypers\nfrom metatrain.utils.data import DatasetInfo, read_systems\nfrom metatrain.utils.neighbor_lists import (\n    get_requested_neighbor_lists,\n    get_system_with_neighbor_lists,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read some sample systems. Metatrain always reads systems in float64, while torch\nuses float32 by default. We will convert the systems to float32.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "systems = read_systems(\"qm9_reduced_100.xyz\")\nsystems = [s.to(torch.float32) for s in systems]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the custom model using the PET architecture as a building block.\nThe dummy architecture here adds a linear layer and a tanh activation function\non top of the PET model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class PETWithTanh(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.pet = PET(\n            get_default_hypers(\"pet\")[\"model\"],\n            DatasetInfo(\n                length_unit=\"angstrom\",\n                atomic_types=[1, 6, 7, 8, 9],\n                targets={},\n            ),\n        )\n        self.linear = torch.nn.Linear(384, 1)\n        self.tanh = torch.nn.Tanh()\n\n    def forward(self, systems):\n        model_outputs = self.pet(\n            systems,\n            {\"features\": ModelOutput()},\n            # ModelOutput(per_atom=True) would give per-atom features\n        )\n        features = model_outputs[\"features\"].block().values\n        return self.tanh(self.linear(features))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can train the custom model. Here is one training step executed with\nsome random targets.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "my_targets = torch.randn(100, 1)\n\n# instantiate the model\nmodel = PETWithTanh()\n\n# all metatrain models require neighbor lists to be present in the input systems\nsystems = [\n    get_system_with_neighbor_lists(sys, get_requested_neighbor_lists(model))\n    for sys in systems\n]\n\n# define an optimizer\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n\n# this is one training step\npredictions = model(systems)\nloss = torch.nn.functional.mse_loss(predictions, my_targets)\nloss.backward()\noptimizer.step()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}