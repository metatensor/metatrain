{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Generating and training an LLPR-derived shallow ensemble model\n\nThis tutorial demonstrates how to generate and, optionally, further train an\nLLPR-derived shallow ensemble model using metatrain. Building on the LLPR approach, this\nmore advanced technique allows for 1) generation of a last-layer ensemble model from an\nLLPR model and 2) gradient-based tuning of ensemble weights using a negative\nlog-likelihood (NLL) loss, often leading to improved uncertainty estimates at the cost\nof further training.\n\nWe first train a baseline model without uncertainties:\n\n.. literalinclude:: options-model.yaml\n   :language: yaml\n\nThen we create an LLPR ensemble model. This involves creating the LLPR model, which is\nvery cheap (one pass through the training data without backpropagation), and then\nsampling last-layer ensemble weights using the LLPR covariance (extremely cheap), as\nexplained in https://arxiv.org/html/2403.02251v1. Specifying `num_ensemble_members`\nenables the latter step in addition to the basic LLPR model.\n\n.. literalinclude:: options-llpr-ensemble.yaml\n   :language: yaml\n\nIn addition, you can decide to perform further backpropagation-based training on the\nresulting shallow ensemble, which is more expensive but can lead to better uncertainty\nestimates. This is done by setting `num_epochs` to the number of epochs that you\nwant to train for.\n\n.. literalinclude:: options-llpr-ensemble-train.yaml\n   :language: yaml\n\nYou can train these models yourself with the following code:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import subprocess\n\nimport ase.io\nimport numpy as np\nfrom metatomic.torch import ModelOutput\nfrom metatomic.torch.ase_calculator import MetatomicCalculator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first train the baseline model without uncertainties, then train the LLPR\nensemble models.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Here, we run training as a subprocess. In practice, you would run this from\n# the command line, e.g., ``mtt train options-model.yaml -o model.pt``.\n\nprint(\"Training baseline model...\")\nsubprocess.run([\"mtt\", \"train\", \"options-model.yaml\", \"-o\", \"model.pt\"], check=True)\n\nprint(\"Training LLPR ensemble model...\")\nsubprocess.run(\n    [\"mtt\", \"train\", \"options-llpr-ensemble.yaml\", \"-o\", \"model-llpr-ens.pt\"],\n    check=True,\n)\n\nprint(\"Training LLPR ensemble model with further backpropagation...\")\nsubprocess.run(\n    [\"mtt\", \"train\", \"options-llpr-ensemble-train.yaml\", \"-o\", \"model-llpr-ens-tr.pt\"],\n    check=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can now use the uncertainties from the LLPR, as well as the ensemble model,\nas follows.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Load some test structures\nstructures = ase.io.read(\"ethanol_reduced_100.xyz\", \":5\")\n\n# Load the ensemble-trained model\ncalc = MetatomicCalculator(\"model-llpr-ens.pt\", extensions_directory=\"extensions/\")\n\n# Get predictions with both ensemble and analytical uncertainties\n# (note that all these quantities are also available per-atom with ``per_atom=True``)\npredictions = calc.run_model(\n    structures,\n    {\n        \"energy\": ModelOutput(per_atom=False),\n        \"energy_uncertainty\": ModelOutput(per_atom=False),  # LLPR analytical\n        \"energy_ensemble\": ModelOutput(per_atom=False),  # ensemble predictions\n    },\n)\n\nenergies = predictions[\"energy\"].block().values.squeeze().cpu().numpy()\nllpr_uncertainties = (\n    predictions[\"energy_uncertainty\"].block().values.squeeze().cpu().numpy()\n)\nensemble_predictions = (\n    predictions[\"energy_ensemble\"].block().values.squeeze().cpu().numpy()\n)\n\n# Calculate ensemble mean and standard deviation\nensemble_mean = np.mean(ensemble_predictions, axis=1)\nensemble_std = np.std(ensemble_predictions, axis=1)\n\nprint(f\"Energies: {energies}\")\nprint(f\"LLPR analytical uncertainties: {llpr_uncertainties}\")\nprint(f\"Ensemble mean: {ensemble_mean}\")\nprint(f\"Ensemble std: {ensemble_std}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}