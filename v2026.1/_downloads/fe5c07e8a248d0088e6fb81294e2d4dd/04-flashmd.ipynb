{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Training or fine-tuning a FlashMD model\n\nThis tutorial demonstrates how to train or fine-tune a FlashMD model for the direct\nprediction of molecular dynamics. This type of model affords faster MD simulations\ncompared to MLIPs by one or two orders of magnitude (https://arxiv.org/abs/2505.19350).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import copy\nimport subprocess\n\nimport ase\nimport ase.build\nimport ase.io\nimport ase.units\nfrom ase.calculators.emt import EMT\nfrom ase.md import VelocityVerlet\nfrom ase.md.langevin import Langevin\nfrom ase.md.velocitydistribution import MaxwellBoltzmannDistribution\nfrom huggingface_hub import hf_hub_download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data generation\n\nFlashMD models train on molecular dynamics trajectories in the NVE ensemble (i.e.,\nmost often with the velocity Verlet integrator). These trajectories can be generated\nwith almost any MD code (i-PI, LAMMPS, etc.). Here, for simplicity, we will use ASE\nand its built-in EMT potential. In reality, you might want to use a more accurate\nbaseline such as ab initio MD or a machine-learned interatomic potential (MLIP).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We start by creating a simple system (a small box of aluminum).\natoms = ase.build.bulk(\"Al\", \"fcc\", cubic=True) * (2, 2, 2)\n\n# We first equilibrate the system at 300K using a Langevin thermostat.\nMaxwellBoltzmannDistribution(atoms, temperature_K=300)\natoms.calc = EMT()\ndyn = Langevin(\n    atoms, 2 * ase.units.fs, temperature_K=300, friction=1 / (100 * ase.units.fs)\n)\ndyn.run(1000)  # 2 ps equilibration (around 10 ps is better in practice)\n\n# Then, we run a production simulation in the NVE ensemble.\ntrajectory = []\n\n\ndef store_trajectory():\n    trajectory.append(copy.deepcopy(atoms))\n\n\ndyn = VelocityVerlet(atoms, 1 * ase.units.fs)\ndyn.attach(store_trajectory, interval=1)\ndyn.run(2000)  # 2 ps NVE run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data preparation\n\nNow, we need to generate the training data from the trajectory. FlashMD models\nrequire future positions and momenta as targets. We will save them in an `.xyz`\nfile under the `future_positions` and `future_momenta` keys.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# The FlashMD model will be trained to predict 32 steps into the future, i.e., 32 fs\n# since we ran the reference simulation with a time step of 1 fs. For this type\n# of system, FlashMD is expected to perform well up to around 60-80 fs.\ntime_lag = 32\n\n# We pick starting structures that are 200 steps apart. To avoid wasting training\n# structures, this should be set to be around the expected velocity-velocity\n# autocorrelation time for the system. This is the time scale that quantifies how long\n# it takes for the system to forget its original velocities.\nspacing = 200\n\n\ndef get_structure_for_dataset(frame_now, frame_ahead):\n    s = copy.deepcopy(frame_now)\n    s.arrays[\"future_positions\"] = frame_ahead.get_positions()\n    s.arrays[\"future_momenta\"] = frame_ahead.get_momenta()\n    return s\n\n\nstructures_for_dataset = []\nfor i in range(0, len(trajectory) - time_lag, spacing):\n    frame_now = trajectory[i]\n    frame_ahead = trajectory[i + time_lag]\n    s = get_structure_for_dataset(frame_now, frame_ahead)\n    structures_for_dataset.append(s)\n\n    # Here, we also add the time-reversed pair (optional)\n    frame_now_trev = copy.deepcopy(frame_now)\n    frame_ahead_trev = copy.deepcopy(frame_ahead)\n    frame_now_trev.set_momenta(-frame_now_trev.get_momenta())\n    frame_ahead_trev.set_momenta(-frame_ahead_trev.get_momenta())\n    s = get_structure_for_dataset(frame_ahead_trev, frame_now_trev)\n    structures_for_dataset.append(s)\n\n# Write the structures to an xyz file\nase.io.write(\"flashmd.xyz\", structures_for_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training the model\n\nThe dataset is now ready for training. You can now provide it to ``metatrain`` and\ntrain your FlashMD model!\n\nFor example, you can use the following options file:\n\n.. literalinclude:: options-flashmd.yaml\n   :language: yaml\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Here, we run training as a subprocess, in reality you would run this from the command\n# line as ``mtt train options-flashmd.yaml``.\nsubprocess.run([\"mtt\", \"train\", \"options-flashmd.yaml\"], check=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fine-tuning a universal pre-trained FlashMD model\n\nFine-tuning is generally recommended over training from scratch, as it drastically\nreduces the amount of training data and training time required to obtain good\nmodels. Here, we demonstrate how to fine-tune a pre-trained FlashMD model on our\naluminum dataset. You just need to add the ``finetune`` section to the training\noptions file, specifying the checkpoint file of the pre-trained model to start from.\n\n.. literalinclude:: options-flashmd-finetune.yaml\n   :language: yaml\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We download the pre-trained model checkpoint from HuggingFace. Make sure the time\n# lag of the pre-trained model matches the one you used to generate your dataset!\nfile_path = hf_hub_download(\n    repo_id=\"lab-cosmo/flashmd\",\n    filename=f\"flashmd_pet-omatpes_{time_lag}fs.ckpt\",\n    local_dir=\".\",\n    local_dir_use_symlinks=False,\n)\n\n# Here, we run training as a subprocess, in reality you would run this from the command\n# line as ``mtt train options-flashmd-finetune.yaml``.\nsubprocess.run([\"mtt\", \"train\", \"options-flashmd-finetune.yaml\"], check=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}