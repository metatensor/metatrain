{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Training a model from scratch\n\nThis tutorial explains how to train a model with ``metatrain`` from scratch and evaluate\nit. :download:`This dataset <ethanol_reduced_100.xyz>` is used here as an example of the\npreferred dataset format. If you have your own dataset, you can simply replace the\ndataset file name with yours.\n\n## Train the model\n\n### Configure the ``options.yaml`` and run the training\nBelow is an example ``options.yaml`` for training a PET model. In order to train other\nmodels, simply replace the architecture name with other models' architecture name. For\nthe supported models, please check `Available Architectures`_ .\n\n\n.. literalinclude:: options-scratch.yaml\n   :language: yaml\n   :linenos:\n\nStart the training by running\n\n```bash\nmtt train options-scratch.yaml\n```\nIt will start training. ``metatrain`` will automatically read the atomic forces from the\ntraining set, if they are stored in it and named as \"forces\". The model can also be\ntrained to learn other properties through transfer learning. For this, please refer to\nthis `transfer learning tutorial`_.\n\n\nOnce the training is started, a folder named ``outputs`` will be created automatically\nunder the folder where you run the command. Under this ``outputs`` folder, there is a\nfolder with the timestamp. Below is a normal structure of that folder of a successful\ntraining run.\n\n```bash\noutputs/2025-10-07/17-08-25/\n\u251c\u2500\u2500 indices  # the results of dataset-spliting\n\u2502   \u251c\u2500\u2500 test.txt\n\u2502   \u251c\u2500\u2500 training.txt\n\u2502   \u2514\u2500\u2500 validation.txt\n\u251c\u2500\u2500 model_0.ckpt  # the intermediate model saved at the 0th training step\n\u251c\u2500\u2500 model.ckpt  # the final model\n\u251c\u2500\u2500 model.pt  # the final model , usable directly by ASE and LAMMPS\n\u251c\u2500\u2500 options_restart.yaml  # an expanded options file\n\u251c\u2500\u2500 train.csv  # structured log of training metrics (loss, MAE, RMSE,...)\n\u2514\u2500\u2500 train.log  # a human-friendly output\n```\nThe ``train.log`` provides information of the training procedure. For example, by\nchecking the following:\n\n```bash\n[2025-10-07 17:08:25][INFO] - Setting up training set [2025-10-07 17:08:25][INFO] -\nForces found in section 'energy', we will use this gradient to train the model\n[2025-10-07 17:08:25][WARNING] - No stress found in section 'energy'.\n```\nYou can know that the forces are identified by ``metatrain`` and are used during the\ntraining, and it fails to find stress. The following provides some statistical of the\ntraining, validation, and the test set\n\n```bash\n[2025-10-07 17:08:25][INFO] - Training dataset:\n    Dataset containing 80 structures Mean and standard deviation of targets: -\n    energy:\n      - mean -9.708e+04 eV\n      - std  3.97 eV\n[2025-10-07 17:08:25][INFO] - Validation dataset:\n    Dataset containing 10 structures Mean and standard deviation of targets: -\n    energy:\n      - mean -9.708e+04 eV\n      - std  3.73 eV\n[2025-10-07 17:08:25][INFO] - Test dataset:\n    Dataset containing 10 structures Mean and standard deviation of targets: -\n    energy:\n      - mean -9.708e+04 eV\n      - std  3.535 eV\n```\nThe training metrics are outputted every epoch, like\n\n```bash\n[2025-10-07 17:08:28][INFO] - Epoch:    0 | learning rate: 0.000e+00 | training\nloss: 6.305e+03 | training energy RMSE (per atom): 884.08 meV | training energy MAE\n(per atom): 773.44 meV | training forces RMSE: 28059.9 meV/A | training forces MAE:\n20581.1 meV/A | validation loss: 7.725e+02 | validation energy RMSE (per atom):\n877.08 meV | validation energy MAE (per atom): 772.04 meV | validation forces RMSE:\n27779.2 meV/A | validation forces MAE: 20201.9 meV/A\n```\nThese metrics are also outputted into ``train.csv`` in a formatted way, which can be\nused for plotting graph like loss curve.\n\nIt is easy to restart the training from the last step, by running\n\n```bash\nmtt train options-scratch.yaml --restart model.ckpt\n```\n## Evaluate the trained model\n\nIn order to evaluate the model on the test set, we can use the mtt eval sub-command.\nFirst, create the input file ``eval-scratch.yaml`` with the following options:\n\n.. literalinclude:: ./eval-scratch.yaml\n   :language: yaml\n   :linenos:\n\nand run (be sure to replace the path to the ``model.pt``)\n\n```bash\nmtt eval model.pt eval-scratch.yaml\n```\nAfter this, a file named ``output.xyz`` will be created, with the atom positions and the\npredicted forces recorded in it. Also, you should see these statistical on your screen\n\n```bash\n[2025-10-07 17:11:47][INFO] - energy RMSE (per atom): 436.50 meV | energy MAE (per\natom): 341.32 meV | forces RMSE: 27823.1 meV/A | forces MAE: 20392.7 meV/A\n[2025-10-07 17:11:47][INFO] - Evaluation time: 1.10 s [1.2185 \u00b1 1.2768 ms per atom]\n```\nFurther analysis can be performed now that the model is trained. We provide a `Python\nscript`_ that can be used to generate a parity plot of the target vs predicted energies,\nbut otherwise leave this open-ended.\n\n\nTo run the script, download it from the repository, modify the paths as necessary\n(indicated with a #TODO), and run. This will generate a plot saved at parity_plot.png.\n\n## Use the model\n\nWith the trained model, you can run molecular dynamics. Please refer to these two\ntutorials for `ASE`_ and `LAMMPS`_ to see how to do that.\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}