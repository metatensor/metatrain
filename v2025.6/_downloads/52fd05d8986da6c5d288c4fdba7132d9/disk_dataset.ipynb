{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Saving a disk dataset\n\nLarge datasets may not fit into memory. In such cases, it is useful to save the\ndataset to disk and load it on the fly during training. This example demonstrates\nhow to save a ``DiskDataset`` for this purpose. Metatrain will then be able to load\n``DiskDataset`` objects saved in this way to execute on-the-fly data loading.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import ase.io\nimport torch\nfrom metatensor.torch import Labels, TensorBlock, TensorMap\nfrom metatensor.torch.atomistic import NeighborListOptions, systems_to_torch\n\nfrom metatrain.utils.data import DiskDatasetWriter\nfrom metatrain.utils.neighbor_lists import get_system_with_neighbor_lists"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As an example, we will use 100 structures from the QM9 dataset. In addition to the\nsystems and targets (here the energy), we also need to save the neighbor lists that\nthe model will use during training.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "disk_dataset_writer = DiskDatasetWriter(\"qm9_reduced_100.zip\")\nfor i in range(100):\n    frame = ase.io.read(\"qm9_reduced_100.xyz\", index=i)\n    system = systems_to_torch(frame, dtype=torch.float64)\n    system = get_system_with_neighbor_lists(\n        system,\n        [NeighborListOptions(cutoff=5.0, full_list=True, strict=True)],\n    )\n    energy = TensorMap(\n        keys=Labels.single(),\n        blocks=[\n            TensorBlock(\n                values=torch.tensor([[frame.info[\"U0\"]]], dtype=torch.float64),\n                samples=Labels(\n                    names=[\"system\"],\n                    values=torch.tensor([[i]]),\n                ),\n                components=[],\n                properties=Labels(\"energy\", torch.tensor([[0]])),\n            )\n        ],\n    )\n    disk_dataset_writer.write_sample(system, {\"energy\": energy})\ndel disk_dataset_writer  # not necessary if the file ends here, but good in general"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset is saved to disk. You can now provide it to ``metatrain`` as a\ndataset to train from, simply by replacing your ``.xyz`` file with the newly created\nzip file (e.g. ``read_from: qm9_reduced_100.zip``).\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}