# These hypers are simply kept in sync with the defaults in MACE,
# except for some metatrain specific hypers.
# They are autogenerated by _gen_hypers.py

architecture:
  name: experimental.mace

  model:
    cutoff: 5.0
    cutoff_width: 0.5 
    # The original MACE 
    {% for item in mace_model_defaults %}
    {{ item[0] }}: {{ item[1] }}
    {% endfor %}
    
  training:
    distributed: false
    distributed_port: 39591
    batch_size: 16
    num_epochs: 1000
    # Optimizer hypers
    optimizer: {{ mace_defaults.optimizer }}
    learning_rate: {{ mace_defaults.lr }}
    weight_decay: {{ mace_defaults.weight_decay }}
    amsgrad: {{ mace_defaults.amsgrad }}
    beta: {{ mace_defaults.beta }}
    # Scheduler hypers
    lr_scheduler: {{ mace_defaults.scheduler }}
    lr_scheduler_gamma: {{ mace_defaults.lr_scheduler_gamma }}
    lr_factor: {{ mace_defaults.lr_factor }}
    lr_scheduler_patience: {{ mace_defaults.scheduler_patience }}
    # Others
    log_interval: 1
    checkpoint_interval: 100
    scale_targets: true
    fixed_composition_weights: {}
    fixed_scaling_weights: {}
    per_structure_targets: []
    num_workers: null
    log_mae: true
    log_separate_blocks: false
    best_model_metric: mae_prod
    grad_clip_norm: 1.0
    loss: mse
