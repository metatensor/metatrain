name: experimental.nanopet

model:
  cutoff: 5.0
  d_pet: 128
  num_heads: 4
  num_attention_layers: 2
  num_gnn_layers: 2
  mlp_dropout_rate: 0.0
  attention_dropout_rate: 0.0
  zbl: False

training:
  distributed: False
  distributed_port: 39591
  batch_size: 16
  num_warmup_steps: 1000
  num_epochs: 10000
  learning_rate: 3e-4
  early_stopping_patience: 1000
  scheduler_patience: 100
  scheduler_factor: 0.8
  log_interval: 10
  checkpoint_interval: 100
  fixed_composition_weights: {}
  per_structure_targets: []
  loss_weights: {}
  log_mae: true
